# Spark

–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
1.1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –≤—ã–≤–æ–¥ —Å—Ö–µ–º—ã: –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª retail_store_sales.csv.  –í—ã–≤–µ–¥–∏—Ç–µ –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ DataFrame –∏ –µ–≥–æ —Å—Ö–µ–º—É (df.printSchema()).

1.2. –û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–æ–ª–±—Ü–æ–≤: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∫ –µ–¥–∏–Ω–æ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É - snake_case.  –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏–π  –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Å—Ö–µ–º—É DataFrame –∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤, 
1.3. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫ –∫–∞–∫–∏–º —Ç–∏–ø–∞–º –¥–∞–Ω–Ω—ã—Ö –æ—Ç–Ω–æ—Å—è—Ç—Å—è –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö –∏ –ø—Ä–∏–≤–µ—Å—Ç–∏ —Å—Ç–æ–ª–±–µ—Ü –∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É —Ç–∏–ø—É. –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ null –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö.

2. –û—á–∏—Å—Ç–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
2.1. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö item: 

–¢–∞–∫ –∫–∞–∫ –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞, —Ç–æ  —Å–æ—Å—Ç–∞–≤–∏—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π DataFrame —Å Category, Item –∏ Rrice Rer Unit.
–î–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, –≥–¥–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ , –Ω–æ –∏–º–µ–µ—Ç—Å—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏ —Ü–µ–Ω–∞ , –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞, –ø—É—Ç—ë–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è (join) —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º —Ç–æ–≤–∞—Ä–æ–≤. –í—ã–≤–µ—Å—Ç–∏ 20 —Å—Ç—Ä–æ–∫, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∏—Ö –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.
2.2. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ Total Spent:  –ù–∞–π—Ç–∏ –≤—Å–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏, —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ –≤ –æ–±—â–µ–π —Å—É–º–º–µ –∏ –æ–±–Ω–æ–≤–∏—Ç—å –µ–µ, –ø–µ—Ä–µ—Å—á–∏—Ç–∞–≤ –µ—ë –∫–∞–∫ quantity * price_per_unit –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π.

2.3. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö Quantity –∏ Rrice Rer Unit: 

–î–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, –≥–¥–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–Ω–∞—á–µ–Ω–∏—è –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø—Ä–æ–¥–∞–Ω–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ , –Ω–æ –∏–º–µ—é—Ç—Å—è —Å—É–º–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∏ —Ü–µ–Ω–∞ –∑–∞ —Ç–æ–≤–∞—Ä , –≤—ã—á–∏—Å–ª–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–∞–Ω–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Ü–µ–ª–æ–º—É —á–∏—Å–ª—É. 
–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ, –µ—Å–ª–∏  –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞ , –Ω–æ –æ–±—â–∞—è —Å—É–º–º–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–º–µ—é—Ç—Å—è, –≤—ã—á–∏—Å–ª–∏—Ç—å —Ü–µ–Ω—É –∑–∞ –µ–¥–∏–Ω–∏—Ü—É –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –û–∫—Ä—É–≥–ª–∏—Ç—å –¥–æ –¥–≤—É—Ö –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π. –í—ã–≤–µ—Å—Ç–∏ 20 —Å—Ç—Ä–æ–∫, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∏—Ö –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.
2.4. –£–¥–∞–ª–∏—Ç—å –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ –≤ Category, Quantity ,Total Spent –∏ Rrice Rer Unit

3. –†–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
3.1. –°–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤: –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü —Ç–æ–≤–∞—Ä–∞  –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¢–æ–ø-5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü. 

3.2. –ê–Ω–∞–ª–∏–∑ —Å—Ä–µ–¥–Ω–µ–≥–æ —á–µ–∫–∞: 
–†–∞—Å—Å—á–∏—Ç–∞–π—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ Total Spent –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞ –æ–ø–ª–∞—Ç—ã. –û–∫—Ä—É–≥–ª–∏—Ç—å –¥–æ –¥–≤—É—Ö –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π.
–†–∞—Å—Å—á–∏—Ç–∞–π—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ Total Spent –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Å—Ç–∞ –≥–¥–µ –ø—Ä–æ—à–ª–∞ –æ–ø–ª–∞—Ç–∞. –û–∫—Ä—É–≥–ª–∏—Ç—å –¥–æ –¥–≤—É—Ö –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π.

4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ 

4.1. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: –î–æ–±–∞–≤–∏—Ç—å –¥–≤–∞ –Ω–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Transaction Date:

day_of_week: –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏
transaction_month: –ú–µ—Å—è—Ü —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ 

---

### ‚úÖ –°—Ç–µ–∫:
1. **Docker + Kafka/ZooKeeper**
2. **Python Producer** ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç JSON-—Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ç–æ–ø–∏–∫ Kafka
3. **Spark Streaming App** ‚Äî —á–∏—Ç–∞–µ—Ç –∏–∑ Kafka, –ø–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –∏ –≤—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å

---

### 1. **–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (Docker + Kafka)**

```yaml
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

–≠—Ç–æ—Ç `docker-compose.yml` –∑–∞–ø—É—Å–∫–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Ç–µ—Ä Kafka –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.

**–ó–∞–ø—É—Å–∫:**
```bash
docker compose up -d
```

---

### 2. **Python Producer**

```python
from kafka import KafkaProducer
import json
import time
import random

producer = KafkaProducer(
    bootstrap_servers='localhost:9092',
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

while True:
    data = {"value": random.randint(1, 100)}
    print("Sending:", data)
    producer.send("test-topic", value=data)
    time.sleep(1)
```

- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É.
- –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–≥–æ –≤ —Ç–æ–ø–∏–∫ `test-topic`.

---

### 3. **Spark Streaming Consumer**

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col
from pyspark.sql.types import StructType, IntegerType

spark = SparkSession.builder \
    .appName("KafkaSparkStreaming") \
    .master("local[*]") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1") \
    .getOrCreate()

schema = StructType().add("value", IntegerType())

df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "test-topic") \
    .load()

parsed = df.selectExpr("CAST(value AS STRING) as json_str") \
    .select(from_json(col("json_str"), schema).alias("data")) \
    .select("data.value")

query = parsed.writeStream \
    .format("console") \
    .outputMode("append") \
    .start()

query.awaitTermination()
```

#### –ß—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç –∫–æ–¥:
1. –ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ Kafka –∫–∞–∫ consumer.
2. –ß–∏—Ç–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Ç–æ–ø–∏–∫–∞ `test-topic`.
3. –ü–∞—Ä—Å–∏—Ç JSON-—Å—Ç—Ä–æ–∫—É –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
4. –í—ã–≤–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Å–æ–ª—å –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.

---

##  –ó–∞–ø—É—Å–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:

1. **–ó–∞–ø—É—Å—Ç–∏—Ç—å Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã:**
   ```bash
   docker compose up -d
   ```

2. **–ó–∞–ø—É—Å—Ç–∏—Ç—å Python Producer:**
   ```bash
   python producer.py
   ```

3. **–ó–∞–ø—É—Å—Ç–∏—Ç—å Spark Streaming –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:**
   ```bash
   spark-submit spark_streaming.py
   ```

---

##  –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏

–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å  —á–∏—Å–ª–∞, —Å–ª–æ–∂–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (—á–µ–∫–∏, —Å–æ–±—ã—Ç–∏—è –∫–ª–∏–∫–æ–≤, –º–µ—Ç—Ä–∏–∫–∏ –¥–∞—Ç—á–∏–∫–æ–≤ –∏ —Ç.–¥.). 
–í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —É—Å–ª–æ–∂–Ω–µ–Ω–∏—è:

---

### üî¢ –ü—Ä–∏–º–µ—Ä —É—Å–ª–æ–∂–Ω–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏:

> –ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ **—á–µ–∫–∏** –∏–∑ –º–∞–≥–∞–∑–∏–Ω–æ–≤, –∫–∞–∂–¥—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç:
- ID –º–∞–≥–∞–∑–∏–Ω–∞
- ID –∫–∞—Å—Å–∏—Ä–∞
- –í—Ä–µ–º—è
- –¢–æ–≤–∞—Ä—ã (–Ω–∞–∑–≤–∞–Ω–∏–µ, –∫–∞—Ç–µ–≥–æ—Ä–∏—è, —Ü–µ–Ω–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)

–í–∞–º –Ω—É–∂–Ω–æ:
1. **–¢–æ–ø-5 –º–∞–≥–∞–∑–∏–Ω–æ–≤ –ø–æ –≤—ã—Ä—É—á–∫–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–µ–∫—É–Ω–¥**
2. **–ß–µ–∫–∏ –¥–æ—Ä–æ–∂–µ 500 —Ä—É–±–ª–µ–π**
3. **–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º**

---

###  –ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å:

1. –ò–∑–º–µ–Ω–∏—Ç—å Producer, —á—Ç–æ–±—ã –æ–Ω –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª —á–µ–∫–∏ (–≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç—ã—Ö —á–∏—Å–µ–ª).
2. –í Spark –∏–∑–º–µ–Ω–∏—Ç—å —Å—Ö–µ–º—É –¥–∞–Ω–Ω—ã—Ö (`StructType`) –ø–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —á–µ–∫–∞.
3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–∫–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é (`window(...)`) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–∞–º.
4. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏ –¥–µ–ª–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (sum, count –∏ —Ç.–¥.).

---

##  –£–ª—É—á—à–µ–Ω–∏—è –≤ Spark Streaming

–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–∫–æ–Ω–Ω–æ–π –∞–≥—Ä–µ–≥–∞—Ü–∏–∏:

```python
from pyspark.sql.functions import window

# –ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è flat_df
windowed_df = batch_df.withWatermark("timestamp", "10 seconds").groupBy(
    window(col("timestamp"), "10 seconds"),
    col("store_name")
).agg(spark_sum("item_total").alias("revenue"))
```
---

##  –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

pipeline:

**–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–æ–±—ã—Ç–∏–π ‚Üí Kafka ‚Üí Spark Streaming ‚Üí –ê–Ω–∞–ª–∏—Ç–∏–∫–∞**

–≠—Ç–æ –æ—Å–Ω–æ–≤–∞ –¥–ª—è –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã—Ö —Å–∏—Å—Ç–µ–º:  
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–¥–∞–∂ –≤ —Ä–∏—Ç–µ–π–ª–µ  
- –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π  
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏  
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ IoT —É—Å—Ç—Ä–æ–π—Å—Ç–≤  

